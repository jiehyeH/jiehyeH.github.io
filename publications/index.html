<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="3MAO3jcAYPrqCbe8CI7asi-37aEVhl_nC6GX9habT9o"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Jihye Hong </title> <meta name="author" content="Jihye Hong"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%BF&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jiehyeh.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Jihye</span> Hong </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> * denotes equal contribution <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://iclr.cc/" rel="external nofollow noopener" target="_blank">ICLR</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/gRNAde-480.webp 480w,/assets/img/publication_preview/gRNAde-800.webp 800w,/assets/img/publication_preview/gRNAde-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/gRNAde.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="gRNAde.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="joshi2025grnade" class="col-sm-8"> <div class="title">gRNAde: Geometric Deep Learning for 3D RNA inverse design</div> <div class="author"> Chaitanya K Joshi, Arian R Jamasb, Ramon Viñas, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Charles Harris, Simon V Mathis, Alex Morehead, Rishabh Anand, Pietro Liò' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>In The Thirteenth International Conference on Learning Representations (ICLR)</em>, 2025 </div> <div class="periodical"> Multi-state geometric RNA sequence design designated as an ICLR spotlight </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/forum?id=lvw3UgeVxS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:dhFuZR0502QC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Computational RNA design tasks are often posed as inverse problems, where sequences are designed based on adopting a single desired secondary structure without considering 3D conformational diversity. We introduce gRNAde, a geometric RNA design pipeline operating on 3D RNA backbones to design sequences that explicitly account for structure and dynamics. gRNAde uses a multi-state Graph Neural Network and autoregressive decoding to generates candidate RNA sequences conditioned on one or more 3D backbone structures where the identities of the bases are unknown. On a single-state fixed backbone re-design benchmark of 14 RNA structures from the PDB identified by Das et al. (2010), gRNAde obtains higher native sequence recovery rates (56% on average) compared to Rosetta (45% on average), taking under a second to produce designs compared to the reported hours for Rosetta. We further demonstrate the utility of gRNAde on a new benchmark of multi-state design for structurally flexible RNAs, as well as zero-shot ranking of mutational fitness landscapes in a retrospective analysis of a recent ribozyme. Experimental wet lab validation on 10 different structured RNA backbones finds that gRNAde has a success rate of 50% at designing pseudoknotted RNA structures, a significant advance over 35% for Rosetta. Open source code and tutorials are available at: github.com/chaitjo/geometric-rna-design.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ISMB</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/FlowDock-480.webp 480w,/assets/img/publication_preview/FlowDock-800.webp 800w,/assets/img/publication_preview/FlowDock-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/FlowDock.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="FlowDock.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2025flowdock" class="col-sm-8"> <div class="title">FlowDock: Geometric Flow Matching for Generative Protein-Ligand Docking and Affinity Prediction</div> <div class="author"> Alex Morehead, and <a href="https://calla.rnet.missouri.edu/cheng/" rel="external nofollow noopener" target="_blank">Jianlin Cheng</a> </div> <div class="periodical"> <em>In Intelligent Systems for Molecular Biology (ISMB)</em>, 2025 </div> <div class="periodical"> First all-atom flow matching model for protein-ligand docking, presented as a CASP16 top-5 method </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2412.10966" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:hFOr9nPyWt4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Powerful generative models of protein-ligand structure have recently been proposed, but few of these methods support both flexible protein-ligand docking and affinity estimation. Of those that do, none can directly model multiple binding ligands concurrently or have been rigorously benchmarked on pharmacologically relevant drug targets, hindering their widespread adoption in drug discovery efforts. In this work, we propose FlowDock, a deep geometric generative model based on conditional flow matching that learns to directly map unbound (apo) structures to their bound (holo) counterparts for an arbitrary number of binding ligands. Furthermore, FlowDock provides predicted structural confidence scores and binding affinity values with each of its generated protein-ligand complex structures, enabling fast virtual screening of new (multi-ligand) drug targets. For the commonly-used PoseBusters Benchmark dataset, FlowDock achieves a 51% blind docking success rate using unbound (apo) protein input structures and without any information derived from multiple sequence alignments, and for the challenging new DockGen-E dataset, FlowDock matches the performance of single-sequence Chai-1 for binding pocket generalization. Additionally, in the ligand category of the 16th community-wide Critical Assessment of Techniques for Structure Prediction (CASP16), FlowDock ranked among the top-5 methods for pharmacological binding affinity estimation across 140 protein-ligand complexes, demonstrating the efficacy of its learned representations in virtual screening. Source code, data, and pre-trained models are available at https://github.com/BioinfoMachineLearning/FlowDock.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Proteins</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/MULTICOM_ligand-480.webp 480w,/assets/img/publication_preview/MULTICOM_ligand-800.webp 800w,/assets/img/publication_preview/MULTICOM_ligand-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/MULTICOM_ligand.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="MULTICOM_ligand.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2025multicom" class="col-sm-8"> <div class="title">Protein-ligand structure and affinity prediction in CASP16 using a geometric deep learning ensemble and flow matching</div> <div class="author"> Alex Morehead, Jian Liu, Pawan Neupane, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Nabin Giri, Jianlin Cheng' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Proteins: Structure, Function, and Bioinformatics</em>, 2025 </div> <div class="periodical"> Deep ensembling for protein-ligand structure and affinity prediction, presented as a CASP16 top-5 method </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://onlinelibrary.wiley.com/doi/10.1002/prot.26827" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:mB3voiENLucC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Predicting the structure of ligands bound to proteins is a foundational problem in modern biotechnology and drug discovery, yet little is known about how to combine the predictions of protein-ligand structure (poses) produced by the latest deep learning methods to identify the best poses and how to accurately estimate the binding affinity between a protein target and a list of ligand candidates. Further, a blind benchmarking and assessment of protein-ligand structure and binding affinity prediction is necessary to ensure it generalizes well to new settings. Towards this end, we introduce MULTICOM_ligand, a deep learning-based protein-ligand structure and binding affinity prediction ensemble featuring structural consensus ranking for unsupervised pose ranking and a new deep generative flow matching model for joint structure and binding affinity prediction. Notably, MULTICOM_ligand ranked among the top-5 ligand prediction methods in both protein-ligand structure prediction and binding affinity prediction in the 16th Critical Assessment of Techniques for Structure Prediction (CASP16), demonstrating its efficacy and utility for real-world drug discovery efforts. The source code for MULTICOM_ligand is freely available on GitHub.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://academic.oup.com/bioinformatics" rel="external nofollow noopener" target="_blank">Bioinformatics</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/GCPNet-480.webp 480w,/assets/img/publication_preview/GCPNet-800.webp 800w,/assets/img/publication_preview/GCPNet-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/GCPNet.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="GCPNet.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2024geometry" class="col-sm-8"> <div class="title">Geometry-Complete Perceptron Networks for 3D Molecular Graphs</div> <div class="author"> Alex Morehead, and <a href="https://calla.rnet.missouri.edu/cheng/" rel="external nofollow noopener" target="_blank">Jianlin Cheng</a> </div> <div class="periodical"> <em>Bioinformatics</em>, 2024 </div> <div class="periodical"> Chirality-aware vector message passing, also presented at the AAAI 2023 DLG (poster) and AI2ASE (oral presentation) workshops </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://academic.oup.com/bioinformatics/article/40/2/btae087/7610880" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:ULOm3_A8WrAC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Motivation: The field of geometric deep learning has recently had a profound impact on several scientific domains such as protein structure prediction and design, leading to methodological advancements within and outside of the realm of traditional machine learning. Within this spirit, in this work, we introduce GCPNET, a new chirality-aware SE(3)-equivariant graph neural network designed for representation learning of 3D biomolecular graphs. We show that GCPNET, unlike previous representation learning methods for 3D biomolecules, is widely applicable to a variety of invariant or equivariant node-level, edge-level, and graph-level tasks on biomolecular structures while being able to (1) learn important chiral properties of 3D molecules and (2) detect external force fields. Results: Across four distinct molecular-geometric tasks, we demonstrate that GCPNET’s predictions (1) for protein–ligand binding affinity achieve a statistically significant correlation of 0.608, more than 5%, greater than current state-of-the-art methods; (2) for protein structure ranking achieve statistically significant target-local and dataset-global correlations of 0.616 and 0.871, respectively; (3) for Newtownian many-body systems modeling achieve a task-averaged mean squared error less than 0.01, more than 15% better than current methods; and (4) for molecular chirality recognition achieve a state-of-the-art prediction accuracy of 98.7%, better than any other machine learning method to date. Availability and implementation: The source code, data, and instructions to train new models or reproduce our results are freely available at https://github.com/BioinfoMachineLearning/GCPNet.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://www.nature.com/commschem/" rel="external nofollow noopener" target="_blank">CommsChem</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/GCDM-480.webp 480w,/assets/img/publication_preview/GCDM-800.webp 800w,/assets/img/publication_preview/GCDM-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/GCDM.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="GCDM.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2024diffusion" class="col-sm-8"> <div class="title">Geometry-Complete Diffusion for 3D Molecule Generation and Optimization</div> <div class="author"> Alex Morehead, and <a href="https://calla.rnet.missouri.edu/cheng/" rel="external nofollow noopener" target="_blank">Jianlin Cheng</a> </div> <div class="periodical"> <em>Nature Communications Chemistry</em>, 2024 </div> <div class="periodical"> Chirality-aware diffusion generative model of 3D molecules, also presented at the ICLR 2023 MLDD workshop </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.nature.com/articles/s42004-024-01233-z" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:M3ejUd6NZC8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Denoising diffusion probabilistic models (DDPMs) have recently taken the field of generative modeling by storm, pioneering new state-of-the-art results in disciplines such as computer vision and computational biology for diverse tasks ranging from text-guided image generation to structure-guided protein design. Along this latter line of research, methods such as those of Hoogeboom et al. 2022 have been proposed for generating 3D molecules using equivariant graph neural networks (GNNs) within a DDPM framework. Toward this end, we propose GCDM, a geometry-complete diffusion model that achieves new state-of-the-art results for 3D molecule diffusion generation by leveraging the representation learning strengths offered by GNNs that perform geometry-complete message-passing. Our results with GCDM also offer preliminary insights into how physical inductive biases impact the generative dynamics of molecular DDPMs. The source code, data, and instructions to train new models or reproduce our results are freely available at https://github.com/BioinfoMachineLearning/Bio-Diffusion.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Protein Science</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/GCPNet-EMA-480.webp 480w,/assets/img/publication_preview/GCPNet-EMA-800.webp 800w,/assets/img/publication_preview/GCPNet-EMA-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/GCPNet-EMA.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="GCPNet-EMA.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2024gcpnet_ema" class="col-sm-8"> <div class="title">Protein Structure Accuracy Estimation using Geometry-Complete Perceptron Networks</div> <div class="author"> Alex Morehead, and <a href="https://calla.rnet.missouri.edu/cheng/" rel="external nofollow noopener" target="_blank">Jianlin Cheng</a> </div> <div class="periodical"> <em>Protein Science</em>, 2024 </div> <div class="periodical"> Follow-up work with GCPNet for fast protein structure accuracy estimation </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/pro.4932" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:9ZlFYXVOiuMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Estimating the accuracy of protein structural models is a critical task in protein bioinformatics. The need for robust methods in the estimation of protein model accuracy (EMA) is prevalent in the field of protein structure prediction, where computationally-predicted structures need to be screened rapidly for the reliability of the positions predicted for each of their amino acid residues and their overall quality. Current methods proposed for EMA are either coupled tightly to existing protein structure prediction methods or evaluate protein structures without sufficiently leveraging the rich, geometric information available in such structures to guide accuracy estimation. In this work, we propose a geometric message passing neural network referred to as the geometry-complete perceptron network for protein structure EMA (GCPNet-EMA), where we demonstrate through rigorous computational benchmarks that GCPNet-EMA’s accuracy estimations are 47% faster and more than 10% (6%) more correlated with ground-truth measures of per-residue (per-target) structural accuracy compared to baseline state-of-the-art methods for tertiary (multimer) structure EMA including AlphaFold 2. The source code and data for GCPNet-EMA are available on GitHub, and a public web server implementation is freely available.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://iclr.cc/" rel="external nofollow noopener" target="_blank">ICLR</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ProteinWorkshop-480.webp 480w,/assets/img/publication_preview/ProteinWorkshop-800.webp 800w,/assets/img/publication_preview/ProteinWorkshop-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/ProteinWorkshop.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ProteinWorkshop.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="jamasb2024evaluating" class="col-sm-8"> <div class="title">Evaluating Representation Learning on the Protein Structure Universe</div> <div class="author"> Arian R. Jamasb<sup>*</sup>, Alex Morehead<sup>*</sup>, Chaitanya K. Joshi<sup>*</sup>, and <span class="more-authors" title="click to view 8 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '8 more authors' ? 'Zuobai Zhang&lt;sup&gt;*&lt;/sup&gt;, Kieran Didi, Simon V. Mathis, Charles Harris, Jian Tang, Jianlin Cheng, Pietro Lio, Tom L. Blundell' : '8 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">8 more authors</span> </div> <div class="periodical"> <em>In The Twelth International Conference on Learning Representations (ICLR)</em>, 2024 </div> <div class="periodical"> Comprehensive benchmarking and experimentation suite for protein representation learning, also presented at the NeurIPS 2023 MLSB workshop </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/forum?id=sTYuRVrdK3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:mVmsd5A6BfQC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>We introduce ProteinWorkshop, a comprehensive benchmark suite for representation learning on protein structures with Geometric Graph Neural Networks. We consider large-scale pre-training and downstream tasks on both experimental and predicted structures to enable the systematic evaluation of the quality of the learned structural representation and their usefulness in capturing functional relationships for downstream tasks. We find that: (1) large-scale pretraining on AlphaFold structures and auxiliary tasks consistently improve the performance of both rotation-invariant and equivariant GNNs, and (2) more expressive equivariant GNNs benefit from pretraining to a greater extent compared to invariant models. We aim to establish a common ground for the machine learning and computational biology communities to rigorously compare and advance protein structure representation learning. Our open-source codebase reduces the barrier to entry for working with large protein structure datasets by providing: (1) storage-efficient dataloaders for large-scale structural databases including AlphaFoldDB and ESM Atlas, as well as (2) utilities for constructing new tasks from the entire PDB. ProteinWorkshop is available at: github.com/a-r-j/ProteinWorkshop.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://ai4sciencecommunity.github.io/" rel="external nofollow noopener" target="_blank">ICML AI4Sci</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/PoseBench-480.webp 480w,/assets/img/publication_preview/PoseBench-800.webp 800w,/assets/img/publication_preview/PoseBench-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/PoseBench.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="PoseBench.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2024posebench" class="col-sm-8"> <div class="title">Deep Learning for Protein-Ligand Docking: Are We There Yet?</div> <div class="author"> Alex Morehead, Nabin Giri, Jian Liu, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Jianlin Cheng' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In ICML AI4Science Workshop</em>, 2024 </div> <div class="periodical"> Comprehensive benchmarking and experimentation suite for protein-ligand docking and structure prediction, selected as a spotlight presentation (top 20% - 30/159) </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2405.14108" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:IWHjjKOFINEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>The effects of ligand binding on protein structures and their in vivo functions carry numerous implications for modern biomedical research and biotechnology development efforts such as drug discovery. Although several deep learning (DL) methods and benchmarks designed for protein-ligand docking have recently been introduced, to date no prior works have systematically studied the behavior of docking methods within the practical context of (1) predicted (apo) protein structures, (2) multiple ligands concurrently binding to a given target protein, and (3) having no prior knowledge of binding pockets. To enable a deeper understanding of docking methods’ real-world utility, we introduce PoseBench, the first comprehensive benchmark for practical protein-ligand docking. PoseBench enables researchers to rigorously and systematically evaluate DL docking methods for apo-to-holo protein-ligand docking and protein-ligand structure generation using both single and multi-ligand benchmark datasets, the latter of which we introduce for the first time to the DL community. Empirically, using PoseBench, we find that all recent DL docking methods but one fail to generalize to multi-ligand protein targets and also that template-based docking algorithms perform equally well or better for multi-ligand docking as recent single-ligand DL docking methods, suggesting areas of improvement for future work. Code, data, tutorials, and benchmark results are available at https://github.com/BioinfoMachineLearning/PoseBench.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://spigmworkshop.github.io/" rel="external nofollow noopener" target="_blank">ICML AI4Sci &amp; SPIGM</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/RNA-FrameFlow-480.webp 480w,/assets/img/publication_preview/RNA-FrameFlow-800.webp 800w,/assets/img/publication_preview/RNA-FrameFlow-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/RNA-FrameFlow.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="RNA-FrameFlow.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="anand2024rna" class="col-sm-8"> <div class="title">RNA-FrameFlow for de novo 3D RNA Backbone Design</div> <div class="author"> Rishabh Anand<sup>*</sup>, Chaitanya K Joshi<sup>*</sup>, Alex Morehead, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Arian R Jamasb, Charles Harris, Simon V Matthis, Kieran Didi, Bryan Hooi, Pietro Liò' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>In ICML AI4Science &amp; SPIGM Workshops</em>, 2024 </div> <div class="periodical"> Conditional flow matching for geometric RNA structure design, selected as a SPIGM (AI4Science) oral (spotlight) presentation </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2406.13839" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:qUcmZB5y_30C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>We introduce RNA-FrameFlow, the first generative model for 3D RNA backbone design. We build upon SE(3) flow matching for protein backbone generation and establish protocols for data preparation and evaluation to address unique challenges posed by RNA modeling. We formulate RNA structures as a set of rigid-body frames and associated loss functions which account for larger, more conformationally flexible RNA backbones (13 atoms per nucleotide) vs. proteins (4 atoms per residue). Toward tackling the lack of diversity in 3D RNA datasets, we explore training with structural clustering and cropping augmentations. Additionally, we define a suite of evaluation metrics to measure whether the generated RNA structures are globally self-consistent (via inverse folding followed by forward folding) and locally recover RNA-specific structural descriptors. The most performant version of RNA-FrameFlow generates locally realistic RNA backbones of 40-150 nucleotides, over 40% of which pass our validity criteria as measured by a self-consistency TM-score &gt;= 0.45, at which two RNAs have the same global fold. Open-source code: https://github.com/rish-16/rna-backbone-design</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CASP15</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/CASP15-CAPRI-480.webp 480w,/assets/img/publication_preview/CASP15-CAPRI-800.webp 800w,/assets/img/publication_preview/CASP15-CAPRI-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/CASP15-CAPRI.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="CASP15-CAPRI.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="https://doi.org/10.1002/prot.26609" class="col-sm-8"> <div class="title">Impact of AlphaFold on structure prediction of protein complexes: The CASP15-CAPRI experiment</div> <div class="author"> Marc F. Lensink, Guillaume Brysbaert, Nessim Raouraoua, and <span class="more-authors" title="click to view 110 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '110 more authors' ? 'Paul A. Bates, Marco Giulini, Rodrigo V. Honorato, Charlotte Noort, Joao M. C. Teixeira, Alexandre M. J. J. Bonvin, Ren Kong, Hang Shi, Xufeng Lu, Shan Chang, Jian Liu, Zhiye Guo, Xiao Chen, Alex Morehead, Raj S. Roy, Tianqi Wu, Nabin Giri, Farhan Quadir, Chen Chen, Jianlin Cheng, Carlos A. Del Carpio, Eichiro Ichiishi, Luis A. Rodriguez-Lumbreras, Juan Fernandez-Recio, Ameya Harmalkar, Lee-Shin Chu, Sam Canner, Rituparna Smanta, Jeffrey J. Gray, Hao Li, Peicong Lin, Jiahua He, Huanyu Tao, Sheng-You Huang, Jorge Roel-Touris, Brian Jimenez-Garcia, Charles W. Christoffer, Anika J. Jain, Yuki Kagaya, Harini Kannan, Tsukasa Nakamura, Genki Terashi, Jacob C. Verburgt, Yuanyuan Zhang, Zicong Zhang, Hayato Fujuta, Masakazu Sekijima, Daisuke Kihara, Omeir Khan, Sergei Kotelnikov, Usman Ghani, Dzmitry Padhorny, Dmitri Beglov, Sandor Vajda, Dima Kozakov, Surendra S. Negi, Tiziana Ricciardelli, Didier Barradas-Bautista, Zhen Cao, Mohit Chawla, Luigi Cavallo, Romina Oliva, Rui Yin, Melyssa Cheung, Johnathan D. Guest, Jessica Lee, Brian G. Pierce, Ben Shor, Tomer Cohen, Matan Halfon, Dina Schneidman-Duhovny, Shaowen Zhu, Rujie Yin, Yuanfei Sun, Yang Shen, Martyna Maszota-Zieleniak, Krzysztof K. Bojarski, Emilia A. Lubecka, Mateusz Marcisz, Annemarie Danielsson, Lukasz Dziadek, Margrethe Gaardlos, Artur Gieldon, Adam Liwo, Sergey A. Samsonov, Rafal Slusarz, Karolina Zieba, Adam K. Sieradzan, Cezary Czaplewski, Shinpei Kobayashi, Yuta Miyakawa, Yasuomi Kiyota, Mayuko Takeda-Shitaka, Kliment Olechnovic, Lukas Valancauskas, Justas Dapkunas, Ceslovas Venclovas, Bjorn Wallner, Lin Yang, Chengyu Hou, Xiaodong He, Shuai Guo, Shenda Jiang, Xiaoliang Ma, Rui Duan, Liming Qui, Xianjin Xu, Xiaoqin Zou, Sameer Velankar, Shoshana J. Wodak' : '110 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">110 more authors</span> </div> <div class="periodical"> <em>Proteins: Structure, Function, and Bioinformatics</em>, 2023 </div> <div class="periodical"> Analysis of the CASP15-CAPRI experiment’s results </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.26609" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:aqlVkmm33-oC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>We present the results for CAPRI Round 54, the 5th joint CASP-CAPRI protein assembly prediction challenge. The Round offered 37 targets, including 14 homodimers, 3 homo-trimers, 13 heterodimers including 3 antibody–antigen complexes, and 7 large assemblies. On average  70 CASP and CAPRI predictor groups, including more than 20 automatics servers, submitted models for each target. A total of 21 941 models submitted by these groups and by 15 CAPRI scorer groups were evaluated using the CAPRI model quality measures and the DockQ score consolidating these measures. The prediction performance was quantified by a weighted score based on the number of models of acceptable quality or higher submitted by each group among their five best models. Results show substantial progress achieved across a significant fraction of the 60+ participating groups. High-quality models were produced for about 40% of the targets compared to 8% two years earlier. This remarkable improvement is due to the wide use of the AlphaFold2 and AlphaFold2-Multimer software and the confidence metrics they provide. Notably, expanded sampling of candidate solutions by manipulating these deep learning inference engines, enriching multiple sequence alignments, or integration of advanced modeling tools, enabled top performing groups to exceed the performance of a standard AlphaFold2-Multimer version used as a yard stick. This notwithstanding, performance remained poor for complexes with antibodies and nanobodies, where evolutionary relationships between the binding partners are lacking, and for complexes featuring conformational flexibility, clearly indicating that the prediction of protein complexes remains a challenging problem.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ISMB</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Gated_Graph_Transformer-480.webp 480w,/assets/img/publication_preview/Gated_Graph_Transformer-800.webp 800w,/assets/img/publication_preview/Gated_Graph_Transformer-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Gated_Graph_Transformer.jpeg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Gated_Graph_Transformer.jpeg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1093/bioinformatics/btad203" class="col-sm-8"> <div class="title">A gated graph transformer for protein complex structure quality assessment and its performance in CASP15</div> <div class="author"> Xiao Chen<sup>*</sup>, Alex Morehead<sup>*</sup>, Jian Liu, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Jianlin Cheng' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Intelligent Systems for Molecular Biology (ISMB)</em>, 2023 </div> <div class="periodical"> Follow-up work to Geometric Transformers, presented at ISMB 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://academic.oup.com/bioinformatics/article/39/Supplement_1/i308/7210460" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:qxL8FJ1GzNcC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Proteins interact to form complexes to carry out essential biological functions. Computational methods such as AlphaFold-multimer have been developed to predict the quaternary structures of protein complexes. An important yet largely unsolved challenge in protein complex structure prediction is to accurately estimate the quality of predicted protein complex structures without any knowledge of the corresponding native structures. Such estimations can then be used to select high-quality predicted complex structures to facilitate biomedical research such as protein function analysis and drug discovery. In this work, we introduce a new gated neighborhood-modulating graph transformer to predict the quality of 3D protein complex structures. It incorporates node and edge gates within a graph transformer framework to control information flow during graph message passing. We trained, evaluated and tested the method (called DProQA) on newly-curated protein complex datasets before the 15th Critical Assessment of Techniques for Protein Structure Prediction (CASP15) and then blindly tested it in the 2022 CASP15 experiment. The method was ranked 3rd among the single-model quality assessment methods in CASP15 in terms of the ranking loss of TM-score on 36 complex targets. The rigorous internal and external experiments demonstrate that DProQA is effective in ranking protein complex structures. The source code, data, and pre-trained models are available at https://github.com/jianlin-cheng/DProQA.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://www.mlsb.io/" rel="external nofollow noopener" target="_blank">NeurIPS MLSB</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/MMDiff-480.webp 480w,/assets/img/publication_preview/MMDiff-800.webp 800w,/assets/img/publication_preview/MMDiff-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/MMDiff.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="MMDiff.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2023towards" class="col-sm-8"> <div class="title">Towards Joint Sequence-Structure Generation of Nucleic Acid and Protein Complexes</div> <div class="author"> Alex Morehead, Aadyot Bhatnagar, Jeffrey A. Ruffolo, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Ali Madani' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In NeurIPS Machine Learning in Structural Biology (MLSB) Workshop</em>, 2023 </div> <div class="periodical"> First generative model of protein and nucleic acid biomolecules </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.mlsb.io/papers_2023/Towards_Joint_Sequence-Structure_Generation_of_Nucleic_Acid_and_Protein_Complexes_with_SE3-Discrete_Diffusion.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:Wp0gIr-vW9MC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Generative models of macromolecules carry abundant and impactful implications for industrial and biomedical efforts in protein engineering. However, existing methods are currently limited to modeling protein structures or sequences, independently or jointly, without regard to the interactions that commonly occur between proteins and other macromolecules. In this work, we introduce MMDiff, a generative model that jointly designs sequences and structures of nucleic acid and protein complexes, independently or in complex, using joint SE(3)-discrete diffusion noise. Such a model has important implications for emerging areas of macromolecular design including structure-based transcription factor design and design of noncoding RNA sequences. We demonstrate the utility of MMDiff through a rigorous new design benchmark for macromolecular complex generation that we introduce in this work. Our results demonstrate that MMDiff is able to successfully generate micro-RNA and single-stranded DNA molecules while being modestly capable of joint modeling DNA and RNA molecules in interaction with multi-chain protein complexes. Source code: https://github.com/Profluent-Internships/MMDiff.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Scientific Data</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/DIPS-Plus.webp" sizes="200px"></source> <img src="/assets/img/publication_preview/DIPS-Plus.webp" class="preview z-depth-1 rounded" width="100%" height="auto" alt="DIPS-Plus.webp" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Morehead_2023" class="col-sm-8"> <div class="title">DIPS-Plus: The enhanced database of interacting protein structures for interface prediction</div> <div class="author"> Alex Morehead, Chen Chen, Ada Sedova, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Jianlin Cheng' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Nature Scientific Data</em>, 2023 </div> <div class="periodical"> At release, the largest annotated dataset of protein-protein structural interactions for machine learning </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.nature.com/articles/s41597-023-02409-3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:roLk4NBRz8UC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>In this work, we expand on a dataset recently introduced for protein interface prediction (PIP), the Database of Interacting Protein Structures (DIPS), to present DIPS-Plus, an enhanced, feature-rich dataset of 42,112 complexes for machine learning of protein interfaces. While the original DIPS dataset contains only the Cartesian coordinates for atoms contained in the protein complex along with their types, DIPS-Plus contains multiple residue-level features including surface proximities, half-sphere amino acid compositions, and new profile hidden Markov model (HMM)-based sequence features for each amino acid, providing researchers a curated feature bank for training protein interface prediction methods. We demonstrate through rigorous benchmarks that training an existing state-of-the-art (SOTA) model for PIP on DIPS-Plus yields new SOTA results, surpassing the performance of some of the latest models trained on residue-level and atom-level encodings of protein complexes to date.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICMLA</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/SSL_with_GNNs_and_DR-480.webp 480w,/assets/img/publication_preview/SSL_with_GNNs_and_DR-800.webp 800w,/assets/img/publication_preview/SSL_with_GNNs_and_DR-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/SSL_with_GNNs_and_DR.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="SSL_with_GNNs_and_DR.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2023semi" class="col-sm-8"> <div class="title">Semi-Supervised Graph Learning Meets Dimensionality Reduction</div> <div class="author"> Alex Morehead<sup>*</sup>, Watchanan Chantapakul<sup>*</sup>, and <a href="https://calla.rnet.missouri.edu/cheng/" rel="external nofollow noopener" target="_blank">Jianlin Cheng</a> </div> <div class="periodical"> <em>In IEEE International Conference on Machine Learning and Applications</em>, 2023 </div> <div class="periodical"> First characterization of the interplay between dimensionality reduction and semi-supervised graph deep learning </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10460069/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:5nxA0vEk-isC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Semi-supervised learning (SSL) has recently received increased attention from machine learning researchers. By enabling effective propagation of known labels in graph-based deep learning (GDL) algorithms, SSL is poised to become an increasingly used technique in GDL in the coming years. However, there are currently few explorations in the graph-based SSL literature on exploiting classical dimensionality reduction techniques for improved label propagation. In this work, we investigate the use of dimensionality reduction techniques such as PCA, t-SNE, and UMAP to see their effect on the performance of graph neural networks (GNNs) designed for semi-supervised propagation of node labels. Our study makes use of benchmark semi-supervised GDL datasets such as the Cora and Citeseer datasets to allow meaningful comparisons of the representations learned by each algorithm when paired with a dimensionality reduction technique. Our comprehensive benchmarks and clus-tering visualizations quantitatively and qualitatively demonstrate that, under certain conditions, employing a priori and a posteriori dimensionality reduction to GNN inputs and outputs, respectively, can simultaneously improve the effectiveness of semi-supervised node label propagation and node clustering. Our source code is freely available on GitHub.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://academic.oup.com/bioinformatics" rel="external nofollow noopener" target="_blank">Bioinformatics</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/EnQA-480.webp 480w,/assets/img/publication_preview/EnQA-800.webp 800w,/assets/img/publication_preview/EnQA-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/EnQA.jpeg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="EnQA.jpeg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1093/bioinformatics/btad030" class="col-sm-8"> <div class="title">3D-equivariant graph neural networks for protein model quality assessment</div> <div class="author"> Chen Chen, Xiao Chen, Alex Morehead, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Tianqi Wu, Jianlin Cheng' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Bioinformatics</em>, 2023 </div> <div class="periodical"> Follow-up to Geometric Transformers introducing line graph message passing to equivariant graph neural networks </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://academic.oup.com/bioinformatics/article-abstract/39/1/btad030/6986970" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:8k81kl-MbHgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Quality assessment (QA) of predicted protein tertiary structure models plays an important role in ranking and using them. With the recent development of deep learning end-to-end protein structure prediction techniques for generating highly confident tertiary structures for most proteins, it is important to explore corresponding QA strategies to evaluate and select the structural models predicted by them since these models have better quality and different properties than the models predicted by traditional tertiary structure prediction methods. We develop EnQA, a novel graph-based 3D-equivariant neural network method that is equivariant to rotation and translation of 3D objects to estimate the accuracy of protein structural models by leveraging the structural features acquired from the state-of-the-art tertiary structure prediction method—AlphaFold2. We train and test the method on both traditional model datasets (e.g. the datasets of the Critical Assessment of Techniques for Protein Structure Prediction) and a new dataset of high-quality structural models predicted only by AlphaFold2 for the proteins whose experimental structures were released recently. Our approach achieves state-of-the-art performance on protein structural models predicted by both traditional protein structure prediction methods and the latest end-to-end deep learning method—AlphaFold2. It performs even better than the model QA scores provided by AlphaFold2 itself. The results illustrate that the 3D-equivariant graph neural network is a promising approach to the evaluation of protein structural models. Integrating AlphaFold2 features with other complementary sequence and structural features is important for improving protein model QA. The source code is available at https://github.com/BioinfoMachineLearning/EnQA.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">bioRxiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Geometric_Mutation_Prediction-480.webp 480w,/assets/img/publication_preview/Geometric_Mutation_Prediction-800.webp 800w,/assets/img/publication_preview/Geometric_Mutation_Prediction-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Geometric_Mutation_Prediction.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Geometric_Mutation_Prediction.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mahmud2023accurate" class="col-sm-8"> <div class="title">Accurate prediction of protein tertiary structural changes induced by single-site mutations with equivariant graph neural networks</div> <div class="author"> Sajid Mahmud, Alex Morehead, and <a href="https://calla.rnet.missouri.edu/cheng/" rel="external nofollow noopener" target="_blank">Jianlin Cheng</a> </div> <div class="periodical"> <em>bioRxiv</em>, 2023 </div> <div class="periodical"> First deep learning method to model single-site structural changes in proteins </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.biorxiv.org/content/10.1101/2023.10.03.560758.abstract" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:4DMP91E08xMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Predicting the change of protein tertiary structure caused by singlesite mutations is important for studying protein structure, function, and interaction. Even though computational protein structure prediction methods such as AlphaFold can predict the overall tertiary structures of most proteins rather accurately, they are not sensitive enough to accurately predict the structural changes induced by single-site amino acid mutations on proteins. Specialized mutation prediction methods mostly focus on predicting the overall stability or function changes caused by mutations without attempting to predict the exact mutation-induced structural changes, limiting their use in protein mutation study. In this work, we develop the first deep learning method based on equivariant graph neural networks (EGNN) to directly predict the tertiary structural changes caused by single-site mutations and the tertiary structure of any protein mutant from the structure of its wild-type counterpart. The results show that it performs substantially better in predicting the tertiary structures of protein mutants than the widely used protein structure prediction method AlphaFold.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICIBM</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/DRLComplex-480.webp 480w,/assets/img/publication_preview/DRLComplex-800.webp 800w,/assets/img/publication_preview/DRLComplex-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/DRLComplex.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="DRLComplex.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="soltanikazemi2023drlcomplex" class="col-sm-8"> <div class="title">DRLComplex: Reconstruction of protein quaternary structures using deep reinforcement learning</div> <div class="author"> Elham Soltanikazemi, Raj S Roy, Farhan Quadir, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Nabin Giri, Alex Morehead, Jianlin Cheng' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In International Conference on Intelligent Biology and Medicine</em>, 2023 </div> <div class="periodical"> First deep Q-learning algorithm for protein complex structure modeling </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2205.13594" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:Zph67rFs4hoC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Predicted inter-chain residue-residue contacts can be used to build the quaternary structure of protein complexes from scratch. However, only a small number of methods have been developed to reconstruct protein quaternary structures using predicted inter-chain contacts. Here, we present an agent-based self-learning method based on deep reinforcement learning (DRLComplex) to build protein complex structures using inter-chain contacts as distance constraints. We rigorously tested DRLComplex on two standard datasets of homodimeric and heterodimeric protein complexes (i.e., the CASP-CAPRI homodimer and Std_32 heterodimer datasets) using both true and predicted interchain contacts as inputs. Utilizing true contacts as input, DRLComplex achieved high average TM-scores of 0.9895 and 0.9881 and a low average interface RMSD (I_RMSD) of 0.2197 and 0.92 on the two datasets, respectively. When predicted contacts are used, the method achieves TM-scores of 0.73 and 0.76 for homodimers and heterodimers, respectively. Our experiments find that the accuracy of reconstructed quaternary structures depends on the accuracy of the contact predictions. Compared to other optimization methods for reconstructing quaternary structures from inter-chain contacts, DRLComplex performs similar to an advanced gradient descent method and better than a Markov Chain Monte Carlo simulation method and a simulated annealing-based method, validating the effectiveness of DRLComplex for quaternary reconstruction of protein complexes.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">bioRxiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Antibody_Design_with_Generative_AI-480.webp 480w,/assets/img/publication_preview/Antibody_Design_with_Generative_AI-800.webp 800w,/assets/img/publication_preview/Antibody_Design_with_Generative_AI-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Antibody_Design_with_Generative_AI.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Antibody_Design_with_Generative_AI.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Shanehsazzadeh2023.01.08.523187" class="col-sm-8"> <div class="title">Unlocking de novo antibody design with generative artificial intelligence</div> <div class="author"> Amir Shanehsazzadeh, Sharrol Bachas, Matt McPartlon, and <span class="more-authors" title="click to view 43 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '43 more authors' ? 'George Kasun, John M. Sutton, Andrea K. Steiger, Richard Shuai, Christa Kohnert, Goran Rakocevic, Jahir M. Gutierrez, Chelsea Chung, Breanna K. Luton, Nicolas Diaz, Simon Levine, Julian Alverio, Bailey Knight, Macey Radach, Alex Morehead, Katherine Bateman, David A. Spencer, Zachary McDargh, Jovan Cejovic, Gaelin Kopec-Belliveau, Robel Haile, Edriss Yassine, Cailen McCloskey, Monica Natividad, Dalton Chapman, Joshua Bennett, Jubair Hossain, Abigail B. Ventura, Gustavo M. Canales, Muttappa Gowda, Kerianne A. Jackson, Jennifer T. Stanton, Marcin Ura, Luka Stojanovic, Engin Yapici, Katherine Moran, Rodante Caguiat, Amber Brown, Shaheed Abdulhaqq, Zheyuan Guo, Lillian R. Klug, Miles Gander, Joshua Meier' : '43 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">43 more authors</span> </div> <div class="periodical"> <em>bioRxiv</em>, 2023 </div> <div class="periodical"> Follow-up work presented at the NeurIPS 2023 MLSB workshop </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.biorxiv.org/content/10.1101/2023.01.08.523187.abstract" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:4TOpqqG69KYC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Generative AI has the potential to redefine the process of therapeutic antibody discovery. In this report, we describe and validate deep generative models for the de novo design of antibodies against human epidermal growth factor receptor (HER2) without additional optimization. The models enabled an efficient workflow that combined in silico design methods with high-throughput experimental techniques to rapidly identify binders from a library of  106 heavy chain complementarity-determining region (HCDR) variants. We demonstrated that the workflow achieves binding rates of 10.6% for HCDR3 and 1.8% for HCDR123 designs and is statistically superior to baselines. We further characterized 421 diverse binders using surface plasmon resonance (SPR), finding 71 with low nanomolar affinity similar to the therapeutic anti-HER2 antibody trastuzumab. A selected subset of 11 diverse high-affinity binders were functionally equivalent or superior to trastuzumab, with most demonstrating suitable developability features. We designed one binder with  3x higher cell-based potency compared to trastuzumab and another with improved cross-species reactivity1. Our generative AI approach unlocks an accelerated path to designing therapeutic antibodies against diverse targets.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://iclr.cc/" rel="external nofollow noopener" target="_blank">ICLR</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Geometric_Transformer-480.webp 480w,/assets/img/publication_preview/Geometric_Transformer-800.webp 800w,/assets/img/publication_preview/Geometric_Transformer-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Geometric_Transformer.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Geometric_Transformer.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2022geometric" class="col-sm-8"> <div class="title">Geometric Transformers for Protein Interface Contact Prediction</div> <div class="author"> Alex Morehead, Chen Chen, and <a href="https://calla.rnet.missouri.edu/cheng/" rel="external nofollow noopener" target="_blank">Jianlin Cheng</a> </div> <div class="periodical"> <em>In The Tenth International Conference on Learning Representations (ICLR)</em>, 2022 </div> <div class="periodical"> Presented a new line graph message passing transformer at ICLR 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/forum?id=CS4463zx6Hi" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:Se3iqnhoufwC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Computational methods for predicting the interface contacts between proteins come highly sought after for drug discovery as they can significantly advance the accuracy of alternative approaches, such as protein-protein docking, protein function analysis tools, and other computational methods for protein bioinformatics. In this work, we present the Geometric Transformer, a novel geometry-evolving graph transformer for rotation and translation-invariant protein interface contact prediction, packaged within DeepInteract, an end-to-end prediction pipeline. DeepInteract predicts partner-specific protein interface contacts (i.e., inter-protein residue-residue contacts) given the 3D tertiary structures of two proteins as input. In rigorous benchmarks, DeepInteract, on challenging protein complex targets from the 13th and 14th CASP-CAPRI experiments as well as Docking Benchmark 5, achieves 14% and 1.1% top L/5 precision (L: length of a protein unit in a complex), respectively. In doing so, DeepInteract, with the Geometric Transformer as its graph-based backbone, outperforms existing methods for interface contact prediction in addition to other graph-based neural network backbones compatible with DeepInteract, thereby validating the effectiveness of the Geometric Transformer for learning rich relational-geometric features for downstream tasks on 3D protein structures.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/EGR-480.webp 480w,/assets/img/publication_preview/EGR-800.webp 800w,/assets/img/publication_preview/EGR-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/EGR.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="EGR.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2022egr" class="col-sm-8"> <div class="title">EGR: Equivariant Graph Refinement and Assessment of 3D Protein Complex Structures</div> <div class="author"> Alex Morehead, Xiao Chen, Tianqi Wu, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Jian Liu, Jianlin Cheng' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>arXiv</em>, 2022 </div> <div class="periodical"> First deep learning method for joint protein-ligand complex structure quality assessment and refinement </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2205.10390" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:KlAtU1dfN6UC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Protein complexes are macromolecules essential to the functioning and well-being of all living organisms. As the structure of a protein complex, in particular its region of interaction between multiple protein subunits (i.e., chains), has a notable influence on the biological function of the complex, computational methods that can quickly and effectively be used to refine and assess the quality of a protein complex’s 3D structure can directly be used within a drug discovery pipeline to accelerate the development of new therapeutics and improve the efficacy of future vaccines. In this work, we introduce the Equivariant Graph Refiner (EGR), a novel E(3)-equivariant graph neural network (GNN) for multi-task structure refinement and assessment of protein complexes. Our experiments on new, diverse protein complex datasets, all of which we make publicly available in this work, demonstrate the state-of-the-art effectiveness of EGR for atomistic refinement and assessment of protein complexes and outline directions for future work in the field. In doing so, we establish a baseline for future studies in macromolecular refinement and structure analysis.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Automated_Retail_Checkout-480.webp 480w,/assets/img/publication_preview/Automated_Retail_Checkout-800.webp 800w,/assets/img/publication_preview/Automated_Retail_Checkout-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Automated_Retail_Checkout.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Automated_Retail_Checkout.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Shoman_2022_CVPR" class="col-sm-8"> <div class="title">A Region-Based Deep Learning Approach to Automated Retail Checkout</div> <div class="author"> Maged Shoman, Armstrong Aboah, Alex Morehead, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Ye Duan, Abdulateef Daud, Yaw Adu-Gyamfi' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>, 2022 </div> <div class="periodical"> Instilling computer vision networks with industrial inductive biases for automated retail checkout </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openaccess.thecvf.com/content/CVPR2022W/AICity/html/Shoman_A_Region-Based_Deep_Learning_Approach_to_Automated_Retail_Checkout_CVPRW_2022_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:MXK_kJrjxJIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Automating the product checkout process at conventional retail stores is a task poised to have large impacts on society generally speaking. Towards this end, reliable deep learning models that enable automated product counting for fast customer checkout can make this goal a reality. In this work, we propose a novel, region-based deep learning approach to automate product counting using a customized YOLOv5 object detection pipeline and the DeepSORT algorithm. Our results on challenging, real-world test videos demonstrate that our method can generalize its predictions to a sufficient level of accuracy and with a fast enough runtime to warrant deployment to real-world commercial settings. Our proposed method won 4th place in the 2022 AI City Challenge, Track 4, with an F1 score of 0.4400 on experimental validation data.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">MLHPC</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Genome-Scale_Protein_Structure-480.webp 480w,/assets/img/publication_preview/Genome-Scale_Protein_Structure-800.webp 800w,/assets/img/publication_preview/Genome-Scale_Protein_Structure-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Genome-Scale_Protein_Structure.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Genome-Scale_Protein_Structure.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="gao_9652872" class="col-sm-8"> <div class="title">High-Performance Deep Learning Toolbox for Genome-Scale Prediction of Protein Structure and Function</div> <div class="author"> Mu Gao, Peik Lund-Andersen, Alex Morehead, and <span class="more-authors" title="click to view 14 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '14 more authors' ? 'Sajid Mahmud, Chen Chen, Xiao Chen, Nabin Giri, Raj S. Roy, Farhan Quadir, T. Chad Effler, Ryan Prout, Subil Abraham, Wael Elwasif, N. Quentin Haas, Jeffrey Skolnick, Jianlin Cheng, Ada Sedova' : '14 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">14 more authors</span> </div> <div class="periodical"> <em>In IEEE/ACM Machine Learning with Graphs in High Performance Computing Environments (MLHPC) Workshop</em>, 2021 </div> <div class="periodical"> A collaboration between the University of Missouri, Oak Ridge National Laboratory, and beyond </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/9652872" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:UebtZRa9Y70C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Computational biology is one of many scientific disciplines ripe for innovation and acceleration with the advent of high-performance computing (HPC). In recent years, the field of machine learning has also seen significant benefits from adopting HPC practices. In this work, we present a novel HPC pipeline that incorporates various machine-learning approaches for structure-based functional annotation of proteins on the scale of whole genomes. Our pipeline makes extensive use of deep learning and provides computational insights into best practices for training advanced deep-learning models for high-throughput data such as proteomics data. We showcase methodologies our pipeline currently supports and detail future tasks for our pipeline to envelop, including large-scale sequence comparison using SAdLSA and prediction of protein tertiary structures using AlphaFold2.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AJUR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Synthetic_Biology-480.webp 480w,/assets/img/publication_preview/Synthetic_Biology-800.webp 800w,/assets/img/publication_preview/Synthetic_Biology-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Synthetic_Biology.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Synthetic_Biology.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kouckyasynthetic" class="col-sm-8"> <div class="title">Synthetic Biology Bicistronic Designs Support Gene Expression Equally Well in vitro and in vivo</div> <div class="author"> Owen Kouckya, Jacob Wagnerb, Sofia Aguilerab, and <span class="more-authors" title="click to view 12 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '12 more authors' ? 'Benjamin Bashawb, Queena Chena, Anthony Eckdahla, Elise Edmanc, Paul Gomeza, Nick Hanlanb, Nick Kempfd, Devin Mattoon, Sam McKlin, Christopher Mazariegos, Alex Morehead, others' : '12 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">12 more authors</span> </div> <div class="periodical"> <em>AJUR</em>, 2020 </div> <div class="periodical"> Part of a collaborative NSF REU between Missouri Western State University and Davidson College </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.academia.edu/download/97784859/AJUR_Vol_17_Issue_1_June_2020_p13.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:2osOgNQ5qMEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Synthetic biology integrates molecular biology tools and an engineering mindset to address challenges in medicine, agriculture, bioremediation, and biomanufacturing. A persistent problem in synthetic biology has been designing genetic circuits that produce predictable levels of protein. In 2013, Mutalik and colleagues developed bicistronic designs (BCDs) that make protein production more predicable in bacterial cells (in vivo). With the growing interest in producing proteins outside of cells (in vitro), we wanted to know if BCDs would work as predictably in cell-free protein synthesis (CFPS) as they do in E. coli cells. We tested 20 BCDs in CFPS and found they performed very similarly in vitro and in vivo. As a step toward developing methods for protein production in artificial cells, we also tested 3 BCDs inside nanoliter-scaled microfluidic droplets. The BCDs worked well in the microfluidic droplets, but their relative protein production levels were not as predictable as expected. These results suggest that the conditions under which gene expression happens in droplets result in a different relationship between genetic control elements such as BCDs and protein production than exists in batch CFPS or in cells.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IEEE BigData</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Gunshot_Detection-480.webp 480w,/assets/img/publication_preview/Gunshot_Detection-800.webp 800w,/assets/img/publication_preview/Gunshot_Detection-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Gunshot_Detection.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Gunshot_Detection.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead_9006456" class="col-sm-8"> <div class="title">Low Cost Gunshot Detection using Deep Learning on the Raspberry Pi</div> <div class="author"> Alex Morehead, Lauren Ogden, Gabe Magee, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Ryan Hosler, Bruce White, George Mohler' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In IEEE International Conference on Big Data</em>, 2019 </div> <div class="periodical"> Tested in real-world settings in Indianapolis, Indiana </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/9006456/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:9yKSN-GCB0IC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Many cities using gunshot detection technology depend on expensive systems that ultimately rely on humans differentiating between gunshots and non-gunshots, such as ShotSpotter. Thus, a scalable gunshot detection system that is low in cost and high in accuracy would be advantageous for a variety of cities across the globe, in that it would favorably promote the delegation of tasks typically worked by humans to machines. A repository of audio data was created from sound clips collected from online audio databases as well as from clips recorded using a USB microphone in residential areas and at a gun range. One-dimensional as well as two-dimensional convolutional neural networks were then trained on this sound data, and spectrograms created from this sound data, to recognize gunshots. These models were deployed to a Raspberry Pi 3 Model B+ with a short message service modem and a USB microphone attached, using a software pipeline to continuously analyze discrete two-second chunks of audio and alert a set of phone numbers if a gunshot is detected in that chunk. Testing found that a majority-rules ensemble of our one-dimensional and two-dimensional models fared best, with an accuracy above 99% on validation data as well as when distinguishing gunshots from fireworks. Besides increasing the safety standards for a city’s residents, the findings generated by this research project expand the current state of knowledge regarding sound-based applications of convolutional neural networks.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jihye Hong. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-69GP935JRL"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'G-69GP935JRL');
  </script> <script defer src="/assets/js/google-analytics-setup.js?12374742c4b1801ba82226e617af7e2d"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>